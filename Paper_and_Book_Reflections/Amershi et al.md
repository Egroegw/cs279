# Amershi et al

This paper is useful for include designers and programmers of Artificial Intelligence-infused products who would like to better design products that meet end user needs by taking advantage of improvement and innovation in AI techniques. The goal of the designers is to produce AI-infused systems that empower users to fulfill their goals with greater efficiency without causing the users excessive additional stress or producing errors. However, an obstacle these designers face is that automated inferences by AI involve uncertainty and produce false positives and negatives. Indeed, "AI-infused sysems may demonstrate unpredictable behaviors that can be disruptive, confusing, ofensive, and even dangerous". AI can cause costly information hiding and work against end user goals. Additionally, while traditional user interface design emphasizes consistency, AI can often by nature be inconsistent.

The need thesis is justified by references to previous research papers, such as [14, 21, 23, 36, 38, 44, 16, 17, 33]. Additionally, the authors infer that the "ongoing stream of articles and editorials in the public domain about how to design in the face of AI" suggests uncertainty on the part of designers about how they can design AI-infused systems. The authors also state that potential design suggestions for AI are often not presented explicitly as such, and that it can also be difficult to understand if and how design guidance stemming from one community or interaction scenario can extend to others. Design suggestions are also scattered among different "academic circles and venues".

The authors produce a set of eighteen guidelines to guide the design of AI-infused systems. The authors synthesized synthesize a unified set of design guidelines from a variety of communities and sources and checked them for applicability to a wide range of scenarios "to validate their applicability and relevance". (The authors consolidated 168 design recommendations into a set of 20 guidelines, before reducing that set down to 18.) The guidelines discuss what should happen when a user initially interacts with a system, when a user is interacting normally, and when something is wrong. Additional guidelines discuss how a system should evolve and improve over time.

The approach thesis is justified by a user study of 49 "design practicianers" who tested the guidelines against 20 popular AI-infused products. While developing the guidelines, the authors used a quasi-heuristic evaluation by asking 11 members of their team to “identify both applications and violations of the proposed guidelines in an interface and to refect on the guidelines themselves during the evaluation" over a one-hour period. (The authors examined 13 AI-infused products in this way.) The 49 design practicianers were asked to evaluate products with respect to guildlines and then evaluate them using a 5-point semantic differential scale from “clearly violated” to “clearly applied”. The AI-infused products were selected using a "maximum-variance" sampling strategy. Finally the guidelines were subject to expert review.

Guidelines and recommendations for how to design "effective human interaction with AI-infused systems" have existed for more than two decades. Certain guidelines, such as those around transparency, have attracted more attention. Other previous work focus on specific scenarios, such as "intelligent context-aware computing systems". A novelty compared to Horvitz's set of principles for mixed-initiative systems (1999) is that the number of principles has increased and the principles have been further expanded upon. A novelty compared to Lee et al [22] is that while Lee's suggestion of caution when updating search list results does not explicitly apply to systems in general, the authors of this paper make their recommendation explicit. A further novelty compared to Lugar and Sellen [26] is that the authors have tried to consolidate their list of recommendations by taking principles from a wide variety of sources.

The authors acknowledge that there is a tradeoff between generality and specialization. If principles are to be more general, they may weaken in power in the particular case, and some of the principles identified by the authors are natually in tension, if not outright conflict. Additionally, the authors also wrote that they optimized their guidelines for generality wherever possible. From a general standpoint, I wonder if specific, domain-dependent principles and guidelines might be superior to overarching and general suggestions: perhaps it would be good to have a central directory to different principles by domain. Of course, the problem with domain-specific principles is additional complexity and perhaps less applicability to systems that span multiple domains.
