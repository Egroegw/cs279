# Horvitz

Horvitz (1999) focuses on the designers of Human-Computer Interaction interfaces and programs (“mixed-initiative user interfaces”) who want “users and intelligent agents” to collaborate efficiently”. (Designers refer to the widest range of people involved in creating the “mixed-initiative user interfaces”, including programmers.) However, it is sometimes difficult for designers and programs to guess at a user’s goals and needs, to consider the costs and benefits of automated action, and to consider how and where a user could add manual control and guide the automated system. In 1999, there had not been much effort expended on expanding the assumption that intelligent services and users could collaboratively work towards the user’s goals. The goal of the designer is to create effective HCI interfaces that assists the user to produce solutions better than solutions that could be created by the user working alone, but while giving the user the ability to control the intelligent agent when it is uncertain about the user’s goals.

The evidence Horvitz shows for the need thesis is by referring to two groups of researchers at the time: one group that enthusiastically developed and applied new kinds of interface agents, and another group that suggested focusing on enhancing a user’s ability to directly manipulate interfaces to access information and invoke services. He states that there was not many focused attempts to leverage advances in both directions, and that the general goal of systems designers should be to seek valuable synergies between both arms.

Horvitz presents a set of 12 principles for designing user interfaces that addresses common problems with the use of agents that are uncertain about a user’s needs. He suggests that the goal of the designers is to genuinely add value to a user through automated services that produce superior solutions than is available to the user working alone. These services should also infer ideal actions to take during uncertainty about a user’s goals. Actions by the services should minimize the cost of wrong guesses about the user’s goals, and should be socially acceptable (not constantly interrupting the user, for instance).

Horvitz uses the LookOut project as evidence for his approach thesis. The goal of LookOut was to assist users in MS Outlook with messaging and scheduling. The user can choose which modality LookOut uses, from fully manual (the user must click on the LookOut icon to activate it) to automated-assistance. Additionally, LookOut acts differently depending on how confident it is about the user’s goals. LookOut allows the user to confirm whether they like the action it proposed, and LookOut will also close itself if the user displays disinterest in its suggested action.

This paper was harder to read as the bulk of it was focused on the example given, namely lookout, while the theoretical understanding and introduction was just one and a half pages long. I’m surprised that even in 1999, there was already capability in LookOut for the user to specify a policy for continual learning on LookOut’s part to improve its ability to guess when it comes to automated scheduling suggestions. Although I wish that the links between LookOut and Horvitz’s theory was more explicit, I have no disagreements with this paper.
